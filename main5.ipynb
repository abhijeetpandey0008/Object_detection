{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2801c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e8d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "GRID_H, GRID_W = 7, 7\n",
    "NUM_BOXES = 2\n",
    "NUM_CLASSES = 1    # single class: \"car\"\n",
    "BATCH = 16\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca55df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"D:\\Downloads\\carDetection\\data\"  # <-- point this at your data folder\n",
    "TRAIN_CSV = os.path.join(DATA_ROOT, 'train_solution_bounding_boxes.csv')\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, 'training_images')\n",
    "TEST_DIR  = os.path.join(DATA_ROOT, 'testing_images')\n",
    "SUB_CSV   = os.path.join(DATA_ROOT, 'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb997acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(csv_path, img_dir):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      images:      np.array, shape (N,IMG_SIZE,IMG_SIZE,3)\n",
    "      boxes_list:  list of arrays (num_boxes,4) in [x1,y1,x2,y2]\n",
    "      labels_list: list of arrays (num_boxes,) with value 1.0\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images, boxes_list, labels_list = [], [], []\n",
    "\n",
    "    for fname, group in df.groupby('image'):\n",
    "        img_path = os.path.join(img_dir, fname)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "\n",
    "        boxes = group[['xmin','ymin','xmax','ymax']].values.astype(np.float32)\n",
    "        labels = np.ones((boxes.shape[0],), dtype=np.float32)\n",
    "\n",
    "        images.append(img)\n",
    "        boxes_list.append(boxes)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return np.array(images), boxes_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2521d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_targets(boxes, labels, img_w=IMG_SIZE, img_h=IMG_SIZE):\n",
    "    target = np.zeros((GRID_H, GRID_W, NUM_BOXES, 5 + NUM_CLASSES), np.float32)\n",
    "    for b, lab in zip(boxes, labels):\n",
    "        cx = (b[0] + b[2]) / (2 * img_w)\n",
    "        cy = (b[1] + b[3]) / (2 * img_h)\n",
    "        w  = (b[2] - b[0]) / img_w\n",
    "        h  = (b[3] - b[1]) / img_h\n",
    "        gx = int(np.clip(np.floor(cx * GRID_W), 0, GRID_W - 1))\n",
    "        gy = int(np.clip(np.floor(cy * GRID_H), 0, GRID_H - 1))\n",
    "\n",
    "        for box_idx in range(NUM_BOXES):\n",
    "            if target[gy, gx, box_idx, 4] == 0:\n",
    "                target[gy, gx, box_idx, 0] = cx * GRID_W - gx\n",
    "                target[gy, gx, box_idx, 1] = cy * GRID_H - gy\n",
    "                target[gy, gx, box_idx, 2] = w\n",
    "                target[gy, gx, box_idx, 3] = h\n",
    "                target[gy, gx, box_idx, 4] = 1.0\n",
    "                target[gy, gx, box_idx, 5] = 1.0 if lab == 1 else 0.0\n",
    "                break\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bbc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(images, boxes_list, labels_list, batch_size, augment=False):\n",
    "    while True:\n",
    "        idxs = np.random.permutation(len(images))\n",
    "        for start in range(0, len(images), batch_size):\n",
    "            batch_idxs = idxs[start:start+batch_size]\n",
    "            batch_imgs, batch_tgts = [], []\n",
    "            for i in batch_idxs:\n",
    "                img = images[i].copy()\n",
    "                boxes, labels = boxes_list[i], labels_list[i]\n",
    "                if augment and np.random.rand()>0.5:\n",
    "                    img = np.fliplr(img)\n",
    "                    boxes[:, [0,2]] = IMG_SIZE - boxes[:, [2,0]]\n",
    "                batch_imgs.append(img)\n",
    "                batch_tgts.append(convert_targets(boxes, labels))\n",
    "            yield np.array(batch_imgs), np.array(batch_tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395bc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_giou(true_corners, pred_corners):\n",
    "    x1 = tf.maximum(true_corners[...,0], pred_corners[...,0])\n",
    "    y1 = tf.maximum(true_corners[...,1], pred_corners[...,1])\n",
    "    x2 = tf.minimum(true_corners[...,2], pred_corners[...,2])\n",
    "    y2 = tf.minimum(true_corners[...,3], pred_corners[...,3])\n",
    "    inter = tf.maximum(0., x2-x1) * tf.maximum(0., y2-y1)\n",
    "    area_t = (true_corners[...,2]-true_corners[...,0]) * (true_corners[...,3]-true_corners[...,1])\n",
    "    area_p = (pred_corners[...,2]-pred_corners[...,0]) * (pred_corners[...,3]-pred_corners[...,1])\n",
    "    union = area_t + area_p - inter + 1e-7\n",
    "    iou = inter / union\n",
    "    ex1 = tf.minimum(true_corners[...,0], pred_corners[...,0])\n",
    "    ey1 = tf.minimum(true_corners[...,1], pred_corners[...,1])\n",
    "    ex2 = tf.maximum(true_corners[...,2], pred_corners[...,2])\n",
    "    ey2 = tf.maximum(true_corners[...,3], pred_corners[...,3])\n",
    "    enc = (ex2-ex1)*(ey2-ey1) + 1e-7\n",
    "    return iou - (enc - union) / enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12739276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_style_loss(y_true, y_pred):\n",
    "    # unpack\n",
    "    true_xy   = y_true[..., :2]\n",
    "    true_wh   = y_true[..., 2:4]\n",
    "    true_conf = y_true[..., 4:5]    # shape [...,1]\n",
    "    true_cls  = y_true[..., 5:]     # shape [...,1]\n",
    "\n",
    "    pred_xy   = y_pred[..., :2]\n",
    "    pred_wh   = y_pred[..., 2:4]\n",
    "    pred_conf = y_pred[..., 4:5]\n",
    "    pred_cls  = y_pred[..., 5:]\n",
    "\n",
    "    # corners for GIoU\n",
    "    t_corners = tf.concat([true_xy - true_wh/2, true_xy + true_wh/2], axis=-1)\n",
    "    p_corners = tf.concat([pred_xy - pred_wh/2, pred_xy + pred_wh/2], axis=-1)\n",
    "    giou = compute_giou(t_corners, p_corners)\n",
    "    # giou_loss = true_conf * (1.0 - giou)[...,tf.newaxis]  # shape [...,1]\n",
    "    giou_loss = tf.maximum(0.0, 1.0 - giou)[...,tf.newaxis]  # shape [...,1]\n",
    "    # masks\n",
    "    obj_mask   = true_conf\n",
    "    noobj_mask = 1.0 - obj_mask\n",
    "\n",
    "    # confidence BCE, then re-expand dims to [...,1]\n",
    "    bce_conf = tf.keras.losses.binary_crossentropy(true_conf, pred_conf)\n",
    "    bce_conf = tf.expand_dims(bce_conf, axis=-1)             # :contentReference[oaicite:2]{index=2}\n",
    "    conf_loss = obj_mask * bce_conf + 0.5 * noobj_mask * bce_conf\n",
    "\n",
    "    # class BCE, re-expand dims\n",
    "    bce_cls   = tf.keras.losses.binary_crossentropy(true_cls, pred_cls)\n",
    "    bce_cls   = tf.expand_dims(bce_cls, axis=-1)\n",
    "    class_loss = obj_mask * bce_cls\n",
    "\n",
    "    # sum all components\n",
    "    total = (giou_loss + conf_loss + class_loss)\n",
    "    return tf.reduce_mean(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb70c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                       input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5560a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = backbone.output\n",
    "x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n",
    "x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n",
    "x = layers.Conv2D(NUM_BOXES*(4+1+NUM_CLASSES),1,padding='same')(x)\n",
    "x = layers.Reshape((GRID_H,GRID_W,NUM_BOXES,5+NUM_CLASSES))(x)\n",
    "\n",
    "xy   = x[..., :2]\n",
    "wh   = x[..., 2:4]\n",
    "conf = layers.Activation('sigmoid')(x[..., 4:5])\n",
    "cls  = layers.Activation('sigmoid')(x[..., 5:])\n",
    "out  = layers.Concatenate(axis=-1)([xy, wh, conf, cls])\n",
    "\n",
    "model = models.Model(backbone.input, out)\n",
    "lr_schedule = optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3, decay_steps=20000, alpha=1e-3)\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss=yolo_style_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da8a1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, boxes, labels = load_data_from_csv(TRAIN_CSV, TRAIN_DIR)\n",
    "train_imgs, val_imgs, train_boxes, val_boxes, train_labels, val_labels = train_test_split(\n",
    "    imgs, boxes, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_gen = data_generator(train_imgs, train_boxes, train_labels, BATCH, augment=True)\n",
    "val_gen   = data_generator(val_imgs,   val_boxes,   val_labels,   BATCH, augment=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22877261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - loss: 49385136.0000 - val_loss: 3.4259\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 3.1130 - val_loss: 2.2314\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 960ms/step - loss: 1.9400 - val_loss: 1.4935\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 948ms/step - loss: 1.4469 - val_loss: 1.3746\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - loss: 1.3633 - val_loss: 1.3386\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 935ms/step - loss: 1944.9539 - val_loss: 1.1550\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 963ms/step - loss: 1.1468 - val_loss: 1.0996\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0878 - val_loss: 1.0592\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 931ms/step - loss: 1.0596 - val_loss: 1.0558\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 952ms/step - loss: 1.0527 - val_loss: 1.0497\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 921ms/step - loss: 1.0521 - val_loss: 1.0475\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 973ms/step - loss: 1.0510 - val_loss: 1.0471\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 946ms/step - loss: 1.0467 - val_loss: 1.0452\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 894ms/step - loss: 1.0471 - val_loss: 1.0431\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 912ms/step - loss: 1.0454 - val_loss: 1.0431\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 1.0429 - val_loss: 1.0421\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0426 - val_loss: 1.0418\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0440 - val_loss: 1.0402\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 934ms/step - loss: 1.0421 - val_loss: 1.0401\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 888ms/step - loss: 1.0426 - val_loss: 1.0429\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 910ms/step - loss: 1.0407 - val_loss: 1.0405\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 886ms/step - loss: 1.0435 - val_loss: 1.0409\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 893ms/step - loss: 1.0397 - val_loss: 1.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 903ms/step - loss: 1.0397 - val_loss: 1.0375\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0371 - val_loss: 1.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - loss: 1.0385 - val_loss: 1.0361\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0389 - val_loss: 1.0320\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 926ms/step - loss: 1.0384 - val_loss: 1.0341\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 918ms/step - loss: 1.0386 - val_loss: 1.0361\n",
      "Epoch 30/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 912ms/step - loss: 1.0371 - val_loss: 1.0322\n",
      "Epoch 31/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 946ms/step - loss: 1.0370 - val_loss: 1.0335\n",
      "Epoch 32/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 887ms/step - loss: 1.0344 - val_loss: 1.0318\n",
      "Epoch 33/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 891ms/step - loss: 1.0357 - val_loss: 1.0321\n",
      "Epoch 34/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 1.0344 - val_loss: 1.0345\n",
      "Epoch 35/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1.0353 - val_loss: 1.0318\n",
      "Epoch 36/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 988ms/step - loss: 1.0350 - val_loss: 1.0329\n",
      "Epoch 37/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 1.0348 - val_loss: 1.0303\n",
      "Epoch 38/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0337 - val_loss: 1.0331\n",
      "Epoch 39/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 891ms/step - loss: 1.0332 - val_loss: 1.0325\n",
      "Epoch 40/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 876ms/step - loss: 1.0352 - val_loss: 1.0329\n",
      "Epoch 41/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 962ms/step - loss: 1.0330 - val_loss: 1.0337\n",
      "Epoch 42/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 890ms/step - loss: 1.0338 - val_loss: 1.0301\n",
      "Epoch 43/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 887ms/step - loss: 1.0331 - val_loss: 1.0336\n",
      "Epoch 44/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 937ms/step - loss: 1.0318 - val_loss: 1.0294\n",
      "Epoch 45/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 1.0327 - val_loss: 1.0316\n",
      "Epoch 46/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 1.0344 - val_loss: 1.0312\n",
      "Epoch 47/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 887ms/step - loss: 1.0327 - val_loss: 1.0343\n",
      "Epoch 48/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 897ms/step - loss: 1.0329 - val_loss: 1.0285\n",
      "Epoch 49/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 884ms/step - loss: 1.0324 - val_loss: 1.0341\n",
      "Epoch 50/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 905ms/step - loss: 1.0313 - val_loss: 1.0310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x284d2672450>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "steps_tr  = len(train_imgs) // BATCH\n",
    "steps_val = len(val_imgs)   // BATCH\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_tr,\n",
    "    validation_steps=steps_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[es, tb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89311f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car_detector.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc703e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
